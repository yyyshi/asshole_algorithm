### 分布式哈希算法
传统取模操作
环形hash
crash算法

原因： 分布式场景下流量大，希望对请求做复杂均衡
常见的复杂均衡策略：
* 1. 随机法
* 2. 轮训和权重轮训
* 3. 取模hash: 不稳定，如果存在节点宕机或者新加入节点，会导致命中率的急剧下降(rehash???)。扩展性极低和容错性极低。是针对一个点的，现在就要在这个点上做创新。
* 4. 一致性hash： 因为hash值为int类型的数值，所以一致性hash的基本思想是，不根据机器数量进行取模，而是根据int类型最大值2^31-1来取模，将整个hash空间模拟成一个环形。这个hash空间由[0-2^31-1]组成。
每个服务器节点负责整个环形虚拟空间中的一个区间，所有的节点组成整个虚拟空间的全集。

普通hash：扩容的代价是很大的，需要全量数据做rehash
而一致性hash相当于将hash中的桶的个数给确定下来了。然后一个节点管理多个桶，通过调整每个节点所管理的桶的个数来处理集群中节点的加入和移出，提高系统的扩展性和容错性。
一致性hash没有考虑到不同的物理机器的异构问题，不能根据机器的处理性能做任务量分发，而且存在热点问题，即当某个节点D存在访问量大的时候，对这个节点D进行扩容，加入一个新的节点E，此时需要从节点D中拷贝部分数据到E，会造成网络负载激增。此时D节点就叫做热点。

虚拟节点主要是为了解决物理节点映射到hash环中出现不均匀的情况。
* 如果虚拟节点映射的好，那么当一个物理节点宕机后，他所负责的请求会平衡的分配给其余的多个物理节点
* 当新加入一个节点的时候，这个节点可以从多个物理节点分担一些请求。

请求尽可能的到达本身就存在请求数据的节点上，即减少网络io。数据本地化。

一致性hash存在的问题：
* 1. 数据倾斜的问题：可以通过添加虚拟节点的方式来平衡。即hash之后不是直接落在物理节点上，而是中间模拟了大量的虚拟节点，将hash后的int值映射到多个虚拟节点(通常设置为32), 然后在通过虚拟节点找到实际的物理节点，提供服务。这在物理节点比较少得场景时候可以解决数据倾斜的问题。
* 2. hash冲突的问题：多个虚拟节点也可以有效的减少hash冲突


redis 中hash slot也是一致性hash的一种实现方式，固定了hash桶的个数，然后用户自定义的管理桶，根据机器性能及请求情况将不同的桶分配给不同的机器。
